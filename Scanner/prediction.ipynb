{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os import listdir\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "INIT_LR = 0.001\n",
    "BS = 32\n",
    "default_image_size = (256, 256)\n",
    "image_size = 0\n",
    "directory_root = \"./PlantVillage\"\n",
    "width = 256\n",
    "height = 256\n",
    "depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_2Darray(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            image = cv2.resize(image, default_image_size)\n",
    "            return img_to_array(image)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Pepper__bell___Bacterial_spot ...\n",
      "[INFO] Processing Pepper__bell___healthy ...\n",
      "[INFO] Processing PlantVillage ...\n",
      "[INFO] Processing Potato___Early_blight ...\n",
      "[INFO] Processing Potato___healthy ...\n",
      "[INFO] Processing Potato___Late_blight ...\n",
      "[INFO] Processing Tomato_Bacterial_spot ...\n",
      "[INFO] Processing Tomato_Early_blight ...\n",
      "[INFO] Processing Tomato_healthy ...\n",
      "[INFO] Processing Tomato_Late_blight ...\n",
      "[INFO] Processing Tomato_Leaf_Mold ...\n",
      "[INFO] Processing Tomato_Septoria_leaf_spot ...\n",
      "[INFO] Processing Tomato_Spider_mites_Two_spotted_spider_mite ...\n",
      "[INFO] Processing Tomato__Target_Spot ...\n",
      "[INFO] Processing Tomato__Tomato_mosaic_virus ...\n",
      "[INFO] Processing Tomato__Tomato_YellowLeaf__Curl_Virus ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "image_list, label_list = [], []\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    root_dir = listdir(directory_root)\n",
    "    for directory in root_dir:\n",
    "        # remove .DS_Store from list\n",
    "        if directory == \".DS_Store\":\n",
    "            root_dir.remove(directory)\n",
    "\n",
    "    plant_disease_folder_list = listdir(f\"{directory_root}/\")\n",
    "    for disease_folder in plant_disease_folder_list:\n",
    "        # remove .DS_Store from list\n",
    "        if disease_folder == \".DS_Store\":\n",
    "            plant_disease_folder_list.remove(disease_folder)\n",
    "    for plant_disease_folder in plant_disease_folder_list:\n",
    "        print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "        plant_disease_image_list = listdir(\n",
    "            f\"{directory_root}/{plant_disease_folder}/\"\n",
    "        )\n",
    "        for single_plant_disease_image in plant_disease_image_list:\n",
    "            if single_plant_disease_image == \".DS_Store\":\n",
    "                plant_disease_image_list.remove(single_plant_disease_image)\n",
    "        for image in plant_disease_image_list[:200]:\n",
    "            image_directory = (\n",
    "                f\"{directory_root}/{plant_disease_folder}/{image}\"\n",
    "            )\n",
    "            if image_directory.endswith(\".jpg\") or image_directory.endswith(\".JPG\"):\n",
    "                image_list.append(convert_image_to_2Darray(image_directory))\n",
    "                label_list.append(plant_disease_folder)\n",
    "    print(\"[INFO] Image loading completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "pickle.dump(label_binarizer, open('label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pepper__bell___Bacterial_spot' 'Pepper__bell___healthy'\n",
      " 'Potato___Early_blight' 'Potato___Late_blight' 'Potato___healthy'\n",
      " 'Tomato_Bacterial_spot' 'Tomato_Early_blight' 'Tomato_Late_blight'\n",
      " 'Tomato_Leaf_Mold' 'Tomato_Septoria_leaf_spot'\n",
      " 'Tomato_Spider_mites_Two_spotted_spider_mite' 'Tomato__Target_Spot'\n",
      " 'Tomato__Tomato_YellowLeaf__Curl_Virus' 'Tomato__Tomato_mosaic_virus'\n",
      " 'Tomato_healthy']\n"
     ]
    }
   ],
   "source": [
    "print(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Spliting data to train, test\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Spliting data to train, test.\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                    np_image_list, \n",
    "                                                    image_labels, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42\n",
    "                                                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range = 25,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range = 0.2, \n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True, \n",
    "    fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "inputShape = (height, width, depth)\n",
    "chanDim = -1\n",
    "\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (depth, height, width)\n",
    "    chanDim = 1\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 85, 85, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 85, 85, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 85, 85, 64)        18496     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 85, 85, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 85, 85, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 85, 85, 64)        36928     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 85, 85, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 85, 85, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 42, 42, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 42, 42, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 42, 42, 128)       73856     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 42, 42, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 42, 42, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 42, 42, 128)       147584    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 42, 42, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 42, 42, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 21, 21, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 21, 21, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 56448)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              57803776  \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                15375     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 15)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,102,671\n",
      "Trainable params: 58,099,791\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Codes\\ProLeafic\\env\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# distribution\n",
    "model.compile(loss = \"binary_crossentropy\", \n",
    "              optimizer = opt,\n",
    "              metrics = [\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Temp\\ipykernel_8760\\948409605.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "73/73 [==============================] - 372s 5s/step - loss: 0.6130 - accuracy: 0.2185 - val_loss: 0.3209 - val_accuracy: 0.0981\n",
      "Epoch 2/25\n",
      "73/73 [==============================] - 330s 5s/step - loss: 0.2400 - accuracy: 0.3607 - val_loss: 0.6458 - val_accuracy: 0.0474\n",
      "Epoch 3/25\n",
      "73/73 [==============================] - 439s 6s/step - loss: 0.2010 - accuracy: 0.4697 - val_loss: 1.4722 - val_accuracy: 0.1506\n",
      "Epoch 4/25\n",
      "73/73 [==============================] - 331s 5s/step - loss: 0.1714 - accuracy: 0.5530 - val_loss: 1.0205 - val_accuracy: 0.0761\n",
      "Epoch 5/25\n",
      "73/73 [==============================] - 318s 4s/step - loss: 0.1428 - accuracy: 0.6423 - val_loss: 0.9461 - val_accuracy: 0.1489\n",
      "Epoch 6/25\n",
      "73/73 [==============================] - 316s 4s/step - loss: 0.1268 - accuracy: 0.6960 - val_loss: 0.8702 - val_accuracy: 0.1387\n",
      "Epoch 7/25\n",
      "73/73 [==============================] - 317s 4s/step - loss: 0.1111 - accuracy: 0.7252 - val_loss: 0.5856 - val_accuracy: 0.2673\n",
      "Epoch 8/25\n",
      "73/73 [==============================] - 315s 4s/step - loss: 0.1052 - accuracy: 0.7471 - val_loss: 0.2829 - val_accuracy: 0.4349\n",
      "Epoch 9/25\n",
      "73/73 [==============================] - 323s 4s/step - loss: 0.0998 - accuracy: 0.7656 - val_loss: 0.3596 - val_accuracy: 0.3739\n",
      "Epoch 10/25\n",
      "73/73 [==============================] - 332s 5s/step - loss: 0.0977 - accuracy: 0.7669 - val_loss: 0.1456 - val_accuracy: 0.7005\n",
      "Epoch 11/25\n",
      "73/73 [==============================] - 318s 4s/step - loss: 0.0910 - accuracy: 0.7922 - val_loss: 0.1812 - val_accuracy: 0.6227\n",
      "Epoch 12/25\n",
      "73/73 [==============================] - 318s 4s/step - loss: 0.0964 - accuracy: 0.7716 - val_loss: 0.1864 - val_accuracy: 0.5854\n",
      "Epoch 13/25\n",
      "73/73 [==============================] - 315s 4s/step - loss: 0.0781 - accuracy: 0.8175 - val_loss: 0.2310 - val_accuracy: 0.4535\n",
      "Epoch 14/25\n",
      "73/73 [==============================] - 323s 4s/step - loss: 0.0871 - accuracy: 0.7973 - val_loss: 1.1318 - val_accuracy: 0.1760\n",
      "Epoch 15/25\n",
      "73/73 [==============================] - 324s 4s/step - loss: 0.0881 - accuracy: 0.7853 - val_loss: 0.5218 - val_accuracy: 0.4704\n",
      "Epoch 16/25\n",
      "73/73 [==============================] - 303s 4s/step - loss: 0.0783 - accuracy: 0.8042 - val_loss: 0.3554 - val_accuracy: 0.4501\n",
      "Epoch 17/25\n",
      "73/73 [==============================] - 301s 4s/step - loss: 0.0669 - accuracy: 0.8574 - val_loss: 0.1249 - val_accuracy: 0.7343\n",
      "Epoch 18/25\n",
      "73/73 [==============================] - 302s 4s/step - loss: 0.0707 - accuracy: 0.8403 - val_loss: 0.2931 - val_accuracy: 0.5262\n",
      "Epoch 19/25\n",
      "73/73 [==============================] - 317s 4s/step - loss: 0.0631 - accuracy: 0.8600 - val_loss: 0.1213 - val_accuracy: 0.6988\n",
      "Epoch 20/25\n",
      "73/73 [==============================] - 312s 4s/step - loss: 0.0615 - accuracy: 0.8643 - val_loss: 0.2231 - val_accuracy: 0.5922\n",
      "Epoch 21/25\n",
      "73/73 [==============================] - 312s 4s/step - loss: 0.0652 - accuracy: 0.8532 - val_loss: 0.1550 - val_accuracy: 0.6734\n",
      "Epoch 22/25\n",
      "73/73 [==============================] - 328s 4s/step - loss: 0.0543 - accuracy: 0.8815 - val_loss: 0.3287 - val_accuracy: 0.5482\n",
      "Epoch 23/25\n",
      "73/73 [==============================] - 324s 4s/step - loss: 0.0575 - accuracy: 0.8781 - val_loss: 0.1317 - val_accuracy: 0.7445\n",
      "Epoch 24/25\n",
      "73/73 [==============================] - 331s 5s/step - loss: 0.0526 - accuracy: 0.8901 - val_loss: 0.0872 - val_accuracy: 0.8122\n",
      "Epoch 25/25\n",
      "73/73 [==============================] - 317s 4s/step - loss: 0.0530 - accuracy: 0.8858 - val_loss: 0.3723 - val_accuracy: 0.5499\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size = BS),\n",
    "    validation_data = (x_test, y_test),\n",
    "    steps_per_epoch = len(x_train) // BS,\n",
    "    epochs=EPOCHS, verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Calculating model accuracy.\n",
      "19/19 [==============================] - 14s 718ms/step - loss: 0.3723 - accuracy: 0.5499\n",
      "Test Accuracy: 54.99153733253479\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Calculating model accuracy.\")\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1] * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model...\n",
      "INFO:tensorflow:Assets written to: ram://75c45bc1-cddb-43df-b877-cda465ab73b3/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] Saving model...\")\n",
    "pickle.dump(model, open(\"cnn_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.models.save_model(model, 'plant_disease_identification.hdf5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "478fd3975707037e390566d82ec487cbc8c7f05c94fbc58e36e0021dc843f55a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
